{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate map tiles from NYC taxi trip data using parallel method\n",
    "\n",
    "在[上一篇文章](https://yeshuanova.github.io/blog/posts/implement-OSM-map-tiles/)中已展示過了簡單建立圖磚資料的方式。本文將改進前篇的圖磚建立方式，加速產生速度以及能處理大檔案。\n",
    "\n",
    "- Concurrency (平行化)\n",
    "    - 使用 [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) 套件將任務平行處理，讓多 CPU 能充分發揮處理能力。\n",
    "    - 盡可能將處理演算法獨立可分散處理的部份盡量平行化。\n",
    "\n",
    "\n",
    "- Large size file (單一大檔案)\n",
    "  - 以 [Divide and Conquer](https://en.wikipedia.org/wiki/Divide_and_conquer_algorithm) 概念來分割檔案並單獨處理，最後再將結果合併。\n",
    "      \n",
    "    \n",
    "- 加速 map tiles 建立速度\n",
    "  - 先建立一個基底 Tiles 後，再由下往上合併的方式 (Bottom-Up)建立新 Tile，避免不必要的運算。\n",
    "\n",
    "\n",
    "- 不使用 Log 方式而使用 [Equalization Histogram](https://en.wikipedia.org/wiki/Histogram_equalization) 繪製 Map tile 來取得較好的繪圖效果。\n",
    "\n",
    "\n",
    "- 不繪製 aggregation 中 count 結果不到 **5** 的點位，避免離散雜訊資料影響結果。\n",
    "\n",
    "## 資料前處理\n",
    "\n",
    "### 下載 NYC Taxi Trip Data\n",
    "\n",
    "使用 `wget` 指令取得 NYC Taxi trip data，這裡一樣使用 2016 年 5 月的資料。\n",
    "\n",
    "```bash\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-05.csv\n",
    "```\n",
    "\n",
    "### 將原始 CSV 分割為小檔案\n",
    "\n",
    "依照資料筆數切割為許多小檔案\n",
    "\n",
    "```bash\n",
    "# 建立 split 資料夾\n",
    "mkdir split\n",
    "\n",
    "# 以 1,000,000 lines 為單位，將原始 csv 檔案分割為數個檔案（不包含 header）\n",
    "tail -n +2 yellow_tripdata_2016-05.csv | split -d -l 1000000 - split/trip.csv.\n",
    "```\n",
    "\n",
    "完成後可得到 `trip.csv.00`，`trip.csv.01` 等不包含標頭的分割檔\n",
    "\n",
    "## 轉換 csv 內容到目標格式\n",
    "\n",
    "將 csv 檔案轉換到包含 Web Mercator 格式座標(epsg:3857)以及所在基底 Tile 的座標資料。\n",
    "\n",
    "- 建立 csv 來源與目標檔案列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, csv, mercantile\n",
    "import gzip, pickle, yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures as futures\n",
    "import datashader as ds\n",
    "\n",
    "from mercantile import Tile\n",
    "\n",
    "source_csvs = glob.glob(os.path.join('split', '*.csv*'))\n",
    "epsg3857_csvs = [os.path.join(f'{os.path.dirname(f)}-epsg3857', os.path.join(os.path.basename(f))) for f in source_csvs]\n",
    "\n",
    "output_folder = os.path.join('map')\n",
    "temp_root = os.path.join(output_folder, 'temp')\n",
    "agg_root = os.path.join(output_folder, 'agg')\n",
    "tile_root = os.path.join(output_folder, 'tile')\n",
    "\n",
    "base_zoom = 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換 source csv 到  target csv file，並將\n",
    "def convTripGpsToWebMercator(source, target, zoom):\n",
    "    os.makedirs(os.path.dirname(target), exist_ok=True)\n",
    "    with open(source, 'r') as cf:\n",
    "        creader = csv.reader(cf, delimiter=',')\n",
    "        with open(target, 'w') as wf:\n",
    "            cwriter = csv.writer(wf, delimiter=',')\n",
    "            cwriter.writerow(['x', 'y', 'zoom', 'xtile', 'ytile'])\n",
    "            for row in creader:\n",
    "                try:\n",
    "                    lng, lat = float(row[5]), float(row[6])\n",
    "                    if (-180.0 <= lng <= 180.0) and (-85.0511 <= lat <= 85.0511):\n",
    "                        x, y = ds.utils.lnglat_to_meters(lng, lat)\n",
    "                        xtile, ytile, tile_zoom = mercantile.tile(lng, lat, zoom)\n",
    "                        cwriter.writerow([x, y, tile_zoom, xtile, ytile])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "def convTripGpsToWebMercatorWrapper(data):\n",
    "    source, target, zoom = data\n",
    "    convTripGpsToWebMercator(source, target, zoom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以 concurrent.futures 同步執行轉換步驟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with futures.ProcessPoolExecutor() as executor:\n",
    "    datas = zip(source_csvs, epsg3857_csvs, [base_zoom] * len(source_csvs))\n",
    "    fs = executor.map(convTripGpsToWebMercatorWrapper, datas)\n",
    "    futures.as_completed(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可得到如下方格式的 csv 檔案\n",
    "\n",
    "| x | y | zoom | xtile  | ytile |\n",
    "|-|-|-|-|:-|\n",
    "| Web Mercator - X | Web Mercator - Y | 地圖基底 zoom | Map Tile X 位置 | Map Tile Y 位置 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 map tile aggregation file\n",
    "\n",
    "建立基底 zoom 中，所有包含資料的 map tile aggregation files\n",
    "\n",
    "- 用 Pandas 讀取分割的 csv 檔案\n",
    "- 執行 Groupby() 計算所需建立的 tile group，避免沒必要的 aggregate 計算\n",
    "- 使用 concurrent.futures 進行平行處理，加快計算速度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得 aggregation file path \n",
    "def getAggFilePath(root, x, y, z):\n",
    "    return os.path.join(root, str(z), str(x), f'{y}.pkl.gz') \n",
    "\n",
    "# 取得 aggregation yaml path\n",
    "def getAggYamlFilePath(root, x, y, z):\n",
    "    return os.path.join(root, str(z), str(x), f'{y}.yaml')\n",
    "\n",
    "# 使用 Pickle 序列化 Aggregation 並儲存成  gzip 格式的檔案\n",
    "def serializeAggToFile(agg, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with gzip.open(file_path, mode='wb') as file:\n",
    "        pickle.dump(agg, file)        \n",
    "\n",
    "# 建立 Aggregation 檔案的 Yaml 檔\n",
    "def serializeAggYaml(agg, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, mode='w') as file:\n",
    "        obj = {\"max_count\": int(agg.values.max())}\n",
    "        yaml.dump(obj, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "\n",
    "# 依照 Tile 位置建立 datashader.Canvas\n",
    "def mapTileCanvas(xtile, ytile, zoom, tile_size=(256, 256)):\n",
    "    bounds = mercantile.xy_bounds(xtile, ytile, zoom)\n",
    "    canvas = ds.Canvas(plot_width = tile_size[0],\n",
    "                       plot_height = tile_size[1],\n",
    "                       x_range = (bounds.left, bounds.right),\n",
    "                       y_range = (bounds.bottom, bounds.top))\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTilesAggregation(source, root):\n",
    "    \n",
    "    if not os.path.exists(source):\n",
    "        raise ValueError(f'Source file {source} doesn\\'t exist')\n",
    "    \n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    \n",
    "    df = pd.read_csv(source,\n",
    "                     usecols=['x', 'y', 'zoom', 'xtile', 'ytile'],\n",
    "                     dtype={'x':np.float32,\n",
    "                            'y':np.float32,\n",
    "                            'zoom':np.int8,\n",
    "                            'xtile':np.int32,\n",
    "                            'ytile':np.int32})\n",
    "    \n",
    "    for ((zoom, xtile, ytile), data) in df.groupby(by=['zoom', 'xtile', 'ytile']):\n",
    "        agg = mapTileCanvas(xtile, ytile, zoom).points(data, 'x', 'y')\n",
    "        serializeAggToFile(agg, getAggFilePath(root, xtile, ytile, zoom))\n",
    "        serializeAggYaml(agg, getAggYamlFilePath(root, xtile, ytile, zoom))\n",
    "        \n",
    "def makeTilesAggregationWrapper(data):\n",
    "    source, root = data\n",
    "    makeTilesAggregation(source, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平行化建立 Map tiles\n",
    "with futures.ProcessPoolExecutor() as executor:\n",
    "    targets_root = [os.path.join(temp_root, os.path.basename(f)) for f in epsg3857_csvs]\n",
    "    \n",
    "    datas = zip(epsg3857_csvs, targets_root)\n",
    "    \n",
    "    fs = executor.map(makeTilesAggregationWrapper, datas)\n",
    "    futures.as_completed(fs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine multiple aggregation\n",
    "\n",
    "合併所有 map tiles aggregation files 成為一個包含所有分割 csv 資料的整合 aggregation 結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由 path 得出 aggregation file 對應的 map tile\n",
    "# Return: (xtile, ytile, zoom)\n",
    "def getTileFromPath(agg_path):\n",
    "    sep = agg_path.split(os.sep)\n",
    "    if len(sep) < 3:\n",
    "        raise ValueError(\"agg_path can not convert to tile path\")        \n",
    "    return (int(sep[-2]), int(sep[-1].split('.')[0]), int(sep[-3]))\n",
    "\n",
    "def readAggregationFile(file):\n",
    "    with gzip.open(file, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得所有需要合併的 map tile 位置\n",
    "def getCombineTiles(folders):    \n",
    "    tile_set = set()\n",
    "    for folder in folders:\n",
    "        tiles = glob.glob(os.path.join(folder, '*', '*', '*.pkl.gz'))\n",
    "        for tile_path in tiles:\n",
    "            x, y, z = getTileFromPath(tile_path)\n",
    "            tile_set.add((x, y, z))\n",
    "    return list(tile_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def combineAggregation(x, y, z, temp_folder, target_folder):\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    files = glob.glob(os.path.join(temp_folder, '*', str(z), str(x), f'{y}.pkl.gz'))\n",
    "    \n",
    "    aggs = map(readAggregationFile, files)\n",
    "    agg = reduce(lambda x, y: x + y, aggs)\n",
    "\n",
    "    serializeAggToFile(agg, getAggFilePath(target_folder, x, y, z))\n",
    "    serializeAggYaml(agg, getAggYamlFilePath(target_folder, x, y, z))\n",
    "\n",
    "def combineAggregationWrapper(datas):\n",
    "    tiles, temp ,target = datas\n",
    "    for tile in tiles:\n",
    "        x, y, z = tile\n",
    "        combineAggregation(x, y, z, temp, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunksSize(num, factor):\n",
    "    s = int(factor * num / os.cpu_count())\n",
    "    return s if s > 0 else 1\n",
    "    \n",
    "def chunks(datas, n):\n",
    "    for i in range(0, len(datas), n):\n",
    "        yield datas[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平行化合併處理方式\n",
    "with futures.ProcessPoolExecutor() as executor:\n",
    "        \n",
    "    tiles = getCombineTiles(glob.glob(os.path.join(temp_root, '*')))\n",
    "    tiles_chunk = list(chunks(tiles, chunksSize(len(tiles), 4)))\n",
    "    tiles_tuple = zip(tiles_chunk, [temp_root] * len(tiles_chunk), [agg_root] * len(tiles_chunk))\n",
    "    \n",
    "    fs = executor.map(combineAggregationWrapper, tiles_tuple)\n",
    "    futures.as_completed(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成後可以得到合併後的基底 map tile 的 aggregation file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Bottom-Up 方式合併並產生新圖層\n",
    "\n",
    "- 從基底 tile 的 aggregation 的檔案中建立 parents tile 列表\n",
    "- 讀取 parents tile 中所有的 child tiles 檔案並合併資料後，在寫入 parents tile\n",
    "  - 如果有的 child tiles 不存在，則建立內部為空值的 map tile\n",
    "- 不斷往上建立 parents tiles 直到完成為止\n",
    "\n",
    "### 範例\n",
    "\n",
    "- 假如現在有一個 tile 座標為 (xtile, ytile, zoom) = (23, 43, 6)，則該 tile 的 parenet tile 為 ptile = (11, 21, 5)。\n",
    "\n",
    "- 而 pTile 的 四個 children tiles 為 (22, 42, 6), (23, 42, 6), (23, 43, 6), (22, 43, 6)。\n",
    "\n",
    "- 因此 pTile 的 aggregation file 可從四個 children tiles 中合併得來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 建立用來讓 canvas 產生 aggregation 的 dummy dataframe\n",
    "dummy_df = pd.DataFrame.from_dict(data={'x':[0], 'y': [0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查是否為使用 gzip 壓縮後的 pickle file\n",
    "def isPickleFile(file):\n",
    "    sep = file.split('.')\n",
    "    if len(sep) < 3:\n",
    "        return False\n",
    "    if sep[-1] != 'gz' or sep[-2] != 'pkl':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 matrix size 縮小一半 (ex. 256x256 -> 128x128)\n",
    "def poolmat(m):\n",
    "    return m[::2, ::2] + m[::2, 1::2] + m[1::2, 1::2] + m[1::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立特定 Tile 的 Aggregation，若不存在則 則回傳 empty aggregation (created by dummy dataframe)\n",
    "def makeTileAggegation(agg_root, tile):\n",
    "    file_path = getAggFilePath(agg_root, *tile)\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            with gzip.open(file_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except:\n",
    "            return mapTileCanvas(*tile).points(dummy_df, 'x', 'y')\n",
    "    else:\n",
    "        return mapTileCanvas(*tile).points(dummy_df, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 以 Bottom-Up 方式建立新的 aggregation data\n",
    "def combineTileButtomUp(agg_root, x, y, z):\n",
    "    \n",
    "    agg = mapTileCanvas(x, y, z).points(dummy_df, 'x', 'y')\n",
    "    \n",
    "    row, col = agg.values.shape\n",
    "    row_c, col_c = int(row/2), int(col/2)\n",
    "    \n",
    "    # lt = left-top, rt = right-top, rb = right-bottom, lb = left-bottom\n",
    "    lt, rt, rb, lb = mercantile.children(Tile(x, y, z)) \n",
    "        \n",
    "    agg.values[0:row_c, 0:col_c] = poolmat(makeTileAggegation(agg_root, lb).values)\n",
    "    agg.values[0:row_c, col_c:col] = poolmat(makeTileAggegation(agg_root, rb).values)\n",
    "    agg.values[row_c:row, col_c:col] = poolmat(makeTileAggegation(agg_root, rt).values)\n",
    "    agg.values[row_c:row, 0:col_c] = poolmat(makeTileAggegation(agg_root, lt).values)\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getParentTiles(root, zoom):\n",
    "    ptile_set = set()\n",
    "    files = glob.glob(os.path.join(root, str(zoom), '*', '*.pkl.gz'))\n",
    "    for x, y, z in map(getTileFromPath, files):\n",
    "        ptile = mercantile.parent(Tile(x, y, z))\n",
    "        ptile_set.add((ptile.x, ptile.y, ptile.z))\n",
    "    \n",
    "    return list(ptile_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTilesBottomUp(root, x, y, z):\n",
    "    agg = combineTileButtomUp(root, x, y, z)\n",
    "    serializeAggToFile(agg, getAggFilePath(root, x, y, z))\n",
    "    serializeAggYaml(agg, getAggYamlFilePath(root, x, y, z))\n",
    "\n",
    "def makeTilesBottomUpWrapper(datas):\n",
    "    for root, x, y, z in datas:\n",
    "        makeTilesBottomUp(root, x, y, z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for zoom in range(base_zoom, 0, -1):\n",
    "    print(f'Make parents tiles from zoom {zoom}')\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        \n",
    "        tiles = [(agg_root, x, y, z) for x, y, z in getParentTiles(agg_root, zoom)]        \n",
    "        tiles_chunk = chunks(tiles, chunksSize(len(tiles), 4))\n",
    "        \n",
    "        fs = executor.map(makeTilesBottomUpWrapper, tiles_chunk)\n",
    "        futures.as_completed(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立每個 zoom 中的點位最大值資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得儲存 Yaml 檔案中，最大點數的資訊\n",
    "def getYamlMaxCount(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        try:\n",
    "            return yaml.load(f)['max_count']\n",
    "        except BaseException:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "# 計算 zoom 中的最大點數資料\n",
    "def getZoomMaxCount(zoom_root):\n",
    "    max_count = 0;\n",
    "    for root, dirs, files in os.walk(zoom_root):\n",
    "        for file in files:\n",
    "            exts = file.split(os.extsep)\n",
    "            \n",
    "            if os.path.splitext(file)[1] != '.yaml':\n",
    "                continue\n",
    "                \n",
    "            mc = getYamlMaxCount(os.path.join(root, file))\n",
    "            max_count = mc if max_count < mc else max_count\n",
    "\n",
    "    return max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for zoom in os.listdir(agg_root):\n",
    "    \n",
    "    max_count = getZoomMaxCount(os.path.join(agg_root, zoom))\n",
    "    zoom_yaml = os.path.join(agg_root, zoom, 'zoom_config.yaml')\n",
    "    \n",
    "    with open(zoom_yaml, 'w') as file:\n",
    "        yaml_obj = {'max_count': max_count}\n",
    "        yaml.dump(yaml_obj, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 產生 Aggregation 檔案對應的 Tile 影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader.transfer_functions as tf\n",
    "from colorcet import fire\n",
    "\n",
    "def getRenderImage(img_root, agg_path):\n",
    "    x, y, z = getTileFromPath(agg_path)\n",
    "    return os.path.join(img_root, f'{z}', f'{x}', f'{y}.png')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 config.yaml 檔建立\n",
    "def getMaxCountDict(root):\n",
    "    max_dict = {}\n",
    "    \n",
    "    for folder in os.listdir(agg_root):\n",
    "        zoom_conf_f = os.path.join(root, folder, 'zoom_config.yaml')\n",
    "        with open(zoom_conf_f, 'r') as f:\n",
    "            try:\n",
    "                obj = yaml.load(f)\n",
    "                max_dict[folder] = int(obj['max_count'])\n",
    "            except ValueError as e:\n",
    "                print('Get max count in zoom ', folder, ': Error')\n",
    "                print(e)\n",
    "    return max_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTileImage(source, target, method='eq_hist', min_pts = 0, max_dict = {}):\n",
    "\n",
    "    if not isPickleFile(source):\n",
    "        return\n",
    "    \n",
    "    with gzip.open(source, 'rb') as f:\n",
    "        \n",
    "        x, y, z = getTileFromPath(source)\n",
    "        os.makedirs(os.path.dirname(target), exist_ok=True)\n",
    "        \n",
    "        agg = pickle.load(f)\n",
    "        \n",
    "        if method == 'eq_hist':\n",
    "            img = tf.shade(agg.where(agg > min_pts), cmap=fire)\n",
    "        elif method == 'log':\n",
    "            img = tf.shade(agg.where(agg > min_pts), cmap=fire, how='log', span=[0, max_dict[str(z)]])\n",
    "        else:\n",
    "            raise ValueError(f'No render method {method}')\n",
    "\n",
    "        with open(target, mode='wb') as out:\n",
    "            out.write(img.to_bytesio(format='png').read())\n",
    "\n",
    "def makeTileImageWrapper(datas):\n",
    "    files, method, min_pts, max_count_dict = datas\n",
    "    for source, target in files:\n",
    "        makeTileImage(source, target, method, min_pts, max_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def renderTileList(agg_root, tile_root):\n",
    "    render_agg_list = glob.glob(os.path.join(agg_root, '*', '*', '*.pkl.gz'))\n",
    "    render_img_list = [getRenderImage(tile_root, agg_path) for agg_path in render_agg_list]\n",
    "    return list(zip(render_agg_list, render_img_list))\n",
    "\n",
    "def parallelData(render_list, method='eq_hist', min_pts=0):\n",
    "    \n",
    "    datas = list(chunks(render_list, chunksSize(len(render_list), 4)))\n",
    "    \n",
    "    method_list = [method] * len(datas)\n",
    "    min_pts_list = [min_pts] * len(datas)\n",
    "    \n",
    "    max_dict = {}\n",
    "    if method == 'log':\n",
    "        max_dict = getMaxCountDict(agg_root)\n",
    "    max_dict_list = [max_dict] * len(datas)\n",
    "    \n",
    "    datas = list(zip(datas, method_list, min_pts_list, max_dict_list))\n",
    "\n",
    "    return datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderMapTiles(agg_root, tile_root, method='eq_hist', min_pts=0):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        render_list = renderTileList(agg_root, tile_root)\n",
    "        datas = parallelData(render_list, method=method, min_pts=min_pts)\n",
    "        \n",
    "        fs = executor.map(makeTileImageWrapper, datas)\n",
    "        futures.as_completed(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate tile images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderMapTiles(agg_root, os.path.join(output_folder, 'tile'))\n",
    "renderMapTiles(agg_root, os.path.join(output_folder, 'tile_log_10p'), method='log', min_pts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Folium 顯示圖層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# 使用 Carto Dark 建立底圖\n",
    "fmap = folium.Map(location=[40.772562, -73.974039],\n",
    "                  tiles='https://cartodb-basemaps-{s}.global.ssl.fastly.net/dark_all/{z}/{x}/{y}.png',\n",
    "                  max_zoom=14,\n",
    "                  zoom_start=12,\n",
    "                  attr='Carto Dark')\n",
    "\n",
    "# 加入放在 GitHub 存放的 map tiles 位置\n",
    "fmap.add_tile_layer(tiles='https://raw.githubusercontent.com/yeshuanova/nyc_taxi_trip_map/master/map/tile/{z}/{x}/{y}.png',\n",
    "                    attr='NYC taxi pickup Heatmap',\n",
    "                    max_zoom=14)\n",
    "\n",
    "# 儲存成 html 檔案\n",
    "fmap.save('index.html')\n",
    "\n",
    "# 顯示地圖\n",
    "fmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
