{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate map tiles from NYC taxi trip data using parallel method\n",
    "\n",
    "在[上一篇文章](https://yeshuanova.github.io/blog/posts/implement-OSM-map-tiles/)中已展示過了簡單建立圖磚資料的方式。本文將改進前篇的圖磚建立方式，加速產生速度以及能處理大檔案。\n",
    "\n",
    "- Concurrency (平行化)\n",
    "    - 使用 [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) 套件將任務平行處理，讓多 CPU 能充分發揮處理能力。\n",
    "    - 盡可能將處理演算法獨立可分散處理的部份盡量平行化。\n",
    "\n",
    "\n",
    "- Large size file (單一大檔案)\n",
    "  - 以 [Divide and Conquer](https://en.wikipedia.org/wiki/Divide_and_conquer_algorithm) 概念來分割檔案並單獨處理，最後再將結果合併。\n",
    "      \n",
    "    \n",
    "- 加速 map tiles 建立速度\n",
    "  - 先建立一個基底 Tiles 後，再由下往上合併的方式 (Bottom-Up)建立新 Tile，避免不必要的運算。\n",
    "\n",
    "\n",
    "- 不使用 Log 方式而使用 [Equalization Histogram](https://en.wikipedia.org/wiki/Histogram_equalization) 繪製 Map tile 來取得較好的繪圖效果。\n",
    "\n",
    "\n",
    "- 不繪製 aggregation 中 count 結果不到 **5** 的點位，避免離散雜訊資料影響結果。\n",
    "\n",
    "## 資料前處理\n",
    "\n",
    "### 下載 NYC Taxi Trip Data\n",
    "\n",
    "使用 `wget` 指令取得 NYC Taxi trip data，這裡一樣使用 2016 年 5 月的資料。\n",
    "\n",
    "```bash\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-05.csv\n",
    "```\n",
    "\n",
    "### 將原始 CSV 分割為小檔案\n",
    "\n",
    "依照資料筆數切割為許多小檔案\n",
    "\n",
    "```bash\n",
    "# 建立 split 資料夾\n",
    "mkdir split\n",
    "\n",
    "# 以 1,000,000 lines 為單位，將原始 csv 檔案分割為數個檔案（不包含 header）\n",
    "tail -n +2 yellow_tripdata_2016-05.csv | split -d -l 1000000 - split/trip.csv.\n",
    "```\n",
    "\n",
    "完成後可得到 `trip.csv.00`，`trip.csv.01` 等不包含標頭的分割檔\n",
    "\n",
    "## 轉換 csv 內容到目標格式\n",
    "\n",
    "將 csv 檔案轉換到包含 Web Mercator 格式座標(epsg:3857)以及所在基底 Tile 的座標資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, csv, mercantile\n",
    "import numpy as np\n",
    "\n",
    "from pyproj import transform, Proj\n",
    "\n",
    "proj_source = Proj(init=\"epsg:4326\") # WGS84\n",
    "proj_target = Proj(init=\"epsg:3857\") # Web mercator\n",
    "\n",
    "def toEpsg3857(lng, lat):\n",
    "    return transform(proj_source, proj_target, lng, lat)\n",
    "\n",
    "def toMapTileCoord(lng, lat, zoom):\n",
    "    tile = mercantile.tile(lng, lat, zoom)\n",
    "    return tile.x, tile.y, tile.z\n",
    "\n",
    "# 轉換 source csv 到  target csv file，並將\n",
    "def convTripGpsToWebMercator(source, target, base_zoom):\n",
    "    os.makedirs(os.path.dirname(target), exist_ok=True)\n",
    "    with open(source, 'r') as cf:\n",
    "        creader = csv.reader(cf, delimiter=',')\n",
    "        with open(target, 'w') as wf:\n",
    "            cwriter = csv.writer(wf, delimiter=',')\n",
    "            cwriter.writerow(['x', 'y', 'zoom', 'xtile', 'ytile'])\n",
    "            for row in creader:\n",
    "                try:\n",
    "                    lat, lng = float(row[6]), float(row[5])\n",
    "                    if (-180.0 <= lng <= 180.0) and (-90.0 <= lat <= 90.0):\n",
    "                        x, y = toEpsg3857(lng, lat)\n",
    "                        xtile, ytile, zoom = toMapTileCoord(lng, lat, base_zoom)\n",
    "                        cwriter.writerow([x, y, zoom, xtile, ytile])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "def convTripGpsToWebMercatorWrapper(tup):\n",
    "    convTripGpsToWebMercator(tup[0], tup[1], tup[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 建立 csv 來源與目標檔案列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_zoom = 15\n",
    "\n",
    "files_parts = glob.glob('./split/*.csv.*')\n",
    "files_conv = [os.path.join('./split/epsg3857', os.path.basename(f)) for f in files_parts]\n",
    "base_zoom_list = [base_zoom] * len(files_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以 Concurrent.futures.ProcessPoolExecutor() 同步執行轉換步驟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as futures\n",
    "\n",
    "with futures.ProcessPoolExecutor() as executor:\n",
    "    tuple_list = list(zip(files_parts, files_conv, base_zoom_list))\n",
    "    fs = executor.map(convTripGpsToWebMercatorWrapper, tuple_list)\n",
    "    futures.as_completed(fs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可得到格式為\n",
    "\n",
    "| x | y | zoom | xtile  | ytile |\n",
    "|-|-|-|-|:-|\n",
    "| Web Mercator - X | Web Mercator - Y | 地圖基底 zoom | Map Tile X 位置 | Map Tile Y 位置 |\n",
    "\n",
    "的 csv 檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 map tile aggregation file\n",
    "\n",
    "建立基底 zoom 中，所有包含資料的 map tile aggregation files\n",
    "\n",
    "- 用 Pandas 讀取分割的 csv 檔案\n",
    "- 執行 Groupby() 計算所需建立的 tile group，避免沒必要的 aggregate 計算\n",
    "- 使用 concurrent.futures 進行平行處理，加快計算速度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, pickle, yaml\n",
    "\n",
    "# 取得 aggregation file path \n",
    "def getAggFilePath(root, x, y, z):\n",
    "    return os.path.join(root, str(z), str(x), str(y) + '.pkl.gz') \n",
    "\n",
    "# 取得 aggregation yaml path\n",
    "def getAggYamlFilePath(root, x, y, z):\n",
    "    return os.path.join(root, str(z), str(x), str(y) + '.yaml')\n",
    "\n",
    "# 使用 Pickle 序列化 Aggregation 並儲存成  gzip 格式的檔案\n",
    "def serializeAggToFile(agg, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with gzip.open(file_path, mode='wb') as file:\n",
    "        pickle.dump(agg, file)        \n",
    "\n",
    "# 建立 Aggregation 檔案的 Yaml 檔\n",
    "def serializeAggYaml(agg, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, mode='w') as file:\n",
    "        obj = {\"max_count\": int(agg.values.max())}\n",
    "        yaml.dump(obj, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "\n",
    "# 依照 Tile 位置建立 datashader.Canvas\n",
    "def mapTileCanvas(xtile, ytile, zoom, tile_size=(256, 256)):\n",
    "    bounds = mercantile.xy_bounds(xtile, ytile, zoom)\n",
    "    canvas = ds.Canvas(plot_width = tile_size[0],\n",
    "                       plot_height = tile_size[1],\n",
    "                       x_range = (bounds.left, bounds.right),\n",
    "                       y_range = (bounds.bottom, bounds.top))\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def makeTilesAggregation(source, agg_root):\n",
    "    \n",
    "    df = pd.read_csv(source, \n",
    "                     usecols=['x', 'y', 'zoom', 'xtile', 'ytile'],\n",
    "                     dtype={'x':np.float32,\n",
    "                            'y':np.float32,\n",
    "                            'zoom':np.int8,\n",
    "                            'xtile':np.int32,\n",
    "                            'ytile':np.int32})\n",
    "    \n",
    "    for ((zoom, xtile, ytile), data) in df.groupby(by=['zoom', 'xtile', 'ytile']):\n",
    "        agg = mapTileCanvas(xtile, ytile, zoom).points(data, 'x', 'y')\n",
    "        serializeAggToFile(agg, getAggFilePath(agg_root, xtile, ytile, zoom))\n",
    "        serializeAggYaml(agg, getAggYamlFilePath(agg_root, xtile, ytile, zoom))\n",
    "        \n",
    "def makeTilesAggregationWrapper(tup):\n",
    "    makeTilesAggregation(tup[0], tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平行化建立 Map tiles\n",
    "with futures.ProcessPoolExecutor() as executor:\n",
    "    csv_source = glob.glob('./split/epsg3857/*')\n",
    "    agg_target = [os.path.join('./map-parallel/agg/temp/', os.path.basename(file)) for file in csv_source]\n",
    "    tuple_list = list(zip(csv_source, agg_target))\n",
    "    \n",
    "    fs = executor.map(makeTilesAggregationWrapper, tuple_list)\n",
    "    futures.as_completed(fs)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine multiple aggregation\n",
    "\n",
    "合併所有 map tiles aggregation files 成為一個包含所有分割 csv 資料的整合 aggregation 結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由 path 得出 aggregation file 對應的 map tile\n",
    "# Return: (xtile, ytile, zoom)\n",
    "def getTileFromPath(agg_path):\n",
    "    sep = agg_path.split(os.sep)\n",
    "    if len(sep) < 3:\n",
    "        raise ValueError(\"agg_path can not convert to tile path\")        \n",
    "    return (int(sep[-2]), int(sep[-1].split('.')[0]), int(sep[-3]))\n",
    "\n",
    "def readAggregationFile(file):\n",
    "    with gzip.open(file, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得所有需要合併的 map tile 位置\n",
    "def getCombinTiles(temp_folder):\n",
    "    tile_set = set()\n",
    "    tiles = glob.glob(os.path.join(temp_folder, '*', '*', '*', '*.pkl.gz'))\n",
    "    for tile_path in tiles:\n",
    "        x, y, z = getTileFromPath(tile_path)\n",
    "        tile_set.add((x, y, z))\n",
    "    return list(tile_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def combineAggregation(x, y, z, temp_folder, target_folder):\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    files = glob.glob(os.path.join(temp_folder, f'*/{z}/{x}/{y}.pkl.gz'))\n",
    "    \n",
    "    aggs = map(readAggregationFile, files)\n",
    "    agg = reduce(lambda x, y: x + y, aggs)\n",
    "\n",
    "    serializeAggToFile(agg, getAggFilePath(target_folder, x, y, z))\n",
    "    serializeAggYaml(agg, getAggYamlFilePath(target_folder, x, y, z))\n",
    "\n",
    "def combineAggregationWrapper(tup):\n",
    "    (x, y, z), temp, target = tup\n",
    "    combineAggregation(x, y, z, temp, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平行化合併處理方式\n",
    "with futures.ProcessPoolExecutor() as executor:\n",
    "    temp_folder = './map-parallel/agg/temp/'\n",
    "    target_folder = './map-parallel/agg/'\n",
    "    tile_list = getCombinTiles(temp_folder)\n",
    "        \n",
    "    tuple_list = list(zip(tile_list, [temp_folder] * len(tile_list), [target_folder] * len(tile_list)))    \n",
    "    fs = executor.map(combineAggregationWrapper, tuple_list)\n",
    "    futures.as_completed(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成後可以得到合併後的基底 map tile 的 aggregation file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Bottom-Up 方式合併並產生新圖層\n",
    "\n",
    "- 從基底 tile 的 aggregation 的檔案中建立 parents tile 列表\n",
    "- 讀取 parents tile 中所有的 child tiles 檔案並合併資料後，在寫入 parents tile\n",
    "  - 如果有的 child tiles 不存在，則建立內部為空值的 map tile\n",
    "- 不斷往上建立 parents tiles 直到完成為止\n",
    "\n",
    "### 範例\n",
    "\n",
    "- 假如現在有一個 tile 座標為 (xtile, ytile, zoom) = (23, 43, 6)，則該 tile 的 parenet tile 為 ptile = (11, 21, 5)。\n",
    "\n",
    "- 而 pTile 的 四個 children tiles 為 (22, 42, 6), (23, 42, 6), (23, 43, 6), (22, 43, 6)。\n",
    "\n",
    "- 因此 pTile 的 aggregation file 可從四個 children tiles 中合併得來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mercantile import Tile\n",
    "\n",
    "# 建立用來讓 canvas 產生 aggregation 的 dummy dataframe\n",
    "dummy_df = pd.DataFrame.from_dict(data={'x':[0], 'y': [0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查是否為使用 gzip 壓縮後的 pickle file\n",
    "def isPickleFile(file):\n",
    "    sep = file.split('.')\n",
    "    if len(sep) < 3:\n",
    "        return False\n",
    "    if sep[-1] != 'gz' or sep[-2] != 'pkl':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 matrix size 縮小一半 (ex. 256x256 -> 128x128)\n",
    "def poolmat(m):\n",
    "    return m[::2, ::2] + m[::2, 1::2] + m[1::2, 1::2] + m[1::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立特定 Tile 的 Aggregation，若不存在則 則回傳 empty aggregation (created by dummy dataframe)\n",
    "def makeTileAggegation(agg_root, tile):\n",
    "    file_path = getAggFilePath(agg_root, *tile)\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            with gzip.open(file_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except:\n",
    "            return mapTileCanvas(*tile).points(dummy_df, 'x', 'y')\n",
    "    else:\n",
    "        return mapTileCanvas(*tile).points(dummy_df, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 以 Bottom-Up 方式建立新的 aggregation data\n",
    "def combineTileButtomUp(agg_root, x, y, z):\n",
    "    \n",
    "    agg = mapTileCanvas(x, y, z).points(dummy_df, 'x', 'y')\n",
    "    \n",
    "    row, col = agg.values.shape\n",
    "    row_c, col_c = int(row/2), int(col/2)\n",
    "    \n",
    "    # lt = left-top, rt = right-top, rb = right-bottom, lb = left-bottom\n",
    "    lt, rt, rb, lb = mercantile.children(Tile(x, y, z)) \n",
    "        \n",
    "    agg.values[0:row_c, 0:col_c] = poolmat(makeTileAggegation(agg_root, lb).values)\n",
    "    agg.values[0:row_c, col_c:col] = poolmat(makeTileAggegation(agg_root, rb).values)\n",
    "    agg.values[row_c:row, col_c:col] = poolmat(makeTileAggegation(agg_root, rt).values)\n",
    "    agg.values[row_c:row, 0:col_c] = poolmat(makeTileAggegation(agg_root, lt).values)\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生 parents tile 列表\n",
    "def getParentTiles(agg_root, base_zoom):\n",
    "    p_tile_set = set()\n",
    "    files = glob.glob(os.path.join(agg_root, str(base_zoom), '*', '*.pkl.gz'))\n",
    "    for x, y, z in map(getTileFromPath, files):\n",
    "        p_tile = mercantile.parent(Tile(x, y, z))\n",
    "        p_tile_set.add((p_tile.x, p_tile.y, p_tile.z))\n",
    "    \n",
    "    return list(p_tile_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTilesBottomUp(agg_root, x, y, z):\n",
    "    agg = combineTileButtomUp(agg_root, x, y, z)\n",
    "    serializeAggToFile(agg, getAggFilePath(agg_root, x, y, z))\n",
    "    serializeAggYaml(agg, getAggYamlFilePath(agg_root, x, y, z))\n",
    "\n",
    "def makeTilesBottomUpWrapper(tuple_obj):\n",
    "    makeTilesBottomUp(*tuple_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import concurrent.futures as futures\n",
    "\n",
    "agg_root = './map-parallel/agg/'\n",
    "\n",
    "for zoom in range(base_zoom, 0, -1):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        its = [(agg_root, x, y, z) for x, y, z in getParentTiles(agg_root, zoom)]\n",
    "        fs = executor.map(makeTilesBottomUpWrapper, its)\n",
    "        futures.as_completed(fs)\n",
    "    print(f'Make parents tiles from zoom {zoom}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 產生 Aggregation 檔案對應的 Tile 影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader.transfer_functions as tf\n",
    "from colorcet import fire\n",
    "\n",
    "def getRenderImage(img_root, agg_path):\n",
    "    x, y, z = getTileFromPath(agg_path)\n",
    "    return os.path.join(img_root, f'{z}', f'{x}', f'{y}.png')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTileImage(source, target):\n",
    "\n",
    "    if not isPickleFile(source):\n",
    "        return\n",
    "    \n",
    "    with gzip.open(source, 'rb') as f:\n",
    "        agg = pickle.load(f)\n",
    "        img = tf.shade(agg.where(agg > 5), cmap=fire)\n",
    "        x, y, z = getTileFromPath(source)\n",
    "        tile_path = os.path.join(tile_root, f'{z}', f'{x}', f'{y}.png')\n",
    "        os.makedirs(os.path.dirname(tile_path), exist_ok=True)\n",
    "        with open(tile_path, mode='wb') as out:\n",
    "            out.write(img.to_bytesio(format='png').read())\n",
    "\n",
    "def makeTileImageWrapper(tup_obj):\n",
    "    makeTileImage(tup_obj[0], tup_obj[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with futures.ProcessPoolExecutor() as executor:\n",
    "    tile_root = './map-parallel/tile/'\n",
    "\n",
    "    render_agg_list = glob.glob(os.path.join(agg_root, '*', '*', '*.pkl.gz'))\n",
    "    render_img_list = [getRenderImage(tile_root, agg_path) for agg_path in render_agg_list]\n",
    "\n",
    "    tup_list = list(zip(render_agg_list, render_img_list))\n",
    "\n",
    "    fs = executor.map(makeTileImageWrapper, tup_list)\n",
    "    futures.as_completed(fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Folium 顯示圖層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# 使用 Carto Dark 建立底圖\n",
    "fmap = folium.Map(location=[40.772562, -73.974039],\n",
    "                  tiles='https://cartodb-basemaps-{s}.global.ssl.fastly.net/dark_all/{z}/{x}/{y}.png',\n",
    "                  max_zoom=15,\n",
    "                  zoom_start=12,\n",
    "                  attr='Carto Dark')\n",
    "\n",
    "# 加入放在 GitHub 存放的 map tiles 位置\n",
    "fmap.add_tile_layer(tiles='https://raw.githubusercontent.com/yeshuanova/nyc_taxi_trip_map/master/map-parallel/tile/{z}/{x}/{y}.png',\n",
    "                    attr='NYC taxi pickup Heatmap',\n",
    "                    max_zoom=15)\n",
    "\n",
    "# 儲存成 html 檔案\n",
    "fmap.save('index-parallel.html')\n",
    "\n",
    "# 顯示地圖\n",
    "fmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
